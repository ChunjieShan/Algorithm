{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,random,shutil\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, random, shutil\n",
    "np.random.seed(7)\n",
    "\n",
    "FOLDER = '../data/'\n",
    "train_data_dir = '../data/train/'\n",
    "val_data_dir = '../data/validation/'\n",
    "train_samples_num = 2250 # train set中全部照片数\n",
    "val_samples_num = 250\n",
    "IMG_W, IMG_H, IMG_CH = 224, 224, 3 # 单张图片的大小\n",
    "batch_size = 50\n",
    "epochs = 50 # 用比较少的epochs数目做演示，节约训练时间\n",
    "class_num = 5 # 此处有5个类别\n",
    "save_folder = '../data/bottleneck/'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此处的训练集和测试集并不是原始图片的train set和test set，而是用VGG16对图片提取的特征，这些特征组成新的train set和test set\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import applications\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255) # 不需图片增强\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.MobileNet(include_top=False, weights='imagenet', input_shape=(224, 224, 3)) \n",
    "    # 使用imagenet的weights作为VGG16的初始weights,由于只是特征提取，故而只取前面的卷积层而不需要DenseLayer，故而include_top=False\n",
    "\n",
    "    generator = datagen.flow_from_directory( # 产生train set\n",
    "        train_data_dir,\n",
    "        target_size=(IMG_W, IMG_H),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical', # 这个地方要修改，要不然出错\n",
    "        shuffle=False) # 必须为False，否则顺序打乱之后，和后面的label对应不上。\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, train_samples_num // batch_size) \n",
    "    np.save(os.path.join(save_folder,'bottleneck_features_train.npy'), bottleneck_features_train)\n",
    "    print('bottleneck features of train set is saved.')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        val_data_dir,\n",
    "        target_size=(IMG_W, IMG_H),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, val_samples_num // batch_size)\n",
    "    np.save(os.path.join(save_folder,'bottleneck_features_val.npy'),bottleneck_features_validation)\n",
    "    print('bottleneck features of test set is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2250 images belonging to 5 classes.\n",
      "bottleneck features of train set is saved.\n",
      "Found 250 images belonging to 5 classes.\n",
      "bottleneck features of test set is saved.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model():\n",
    "    '''\n",
    "    自定义一个模型，该模型仅仅相当于一个分类器，只包含有全连接层，对提取的特征进行分类即可\n",
    "    :return:\n",
    "    '''\n",
    "    # 模型的结构\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "#     model.add(Flatten(input_shape=train_data.shape[1:])) # 将所有data进行flatten\n",
    "#     model.add(Dense(256, activation='relu')) # 256个全连接单元\n",
    "#     model.add(Dropout(0.5)) # dropout正则\n",
    "\n",
    "    model.add(Dense(class_num, activation='softmax')) # 与二分类不同之处：要用Dense(class_num)和softmax\n",
    "\n",
    "    # 模型的配置\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy']) # model的optimizer等\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "45/45 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.8680 - val_loss: 0.1349 - val_accuracy: 0.9760\n",
      "Epoch 2/50\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 0.1307 - accuracy: 0.9667 - val_loss: 0.0740 - val_accuracy: 0.9760\n",
      "Epoch 3/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9796 - val_loss: 0.0531 - val_accuracy: 0.9840\n",
      "Epoch 4/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9853 - val_loss: 0.0635 - val_accuracy: 0.9760\n",
      "Epoch 5/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0378 - accuracy: 0.9911 - val_loss: 0.0445 - val_accuracy: 0.9800\n",
      "Epoch 6/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0269 - accuracy: 0.9947 - val_loss: 0.0408 - val_accuracy: 0.9880\n",
      "Epoch 7/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9973 - val_loss: 0.0485 - val_accuracy: 0.9760\n",
      "Epoch 8/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9978 - val_loss: 0.0442 - val_accuracy: 0.9840\n",
      "Epoch 9/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0493 - val_accuracy: 0.9800\n",
      "Epoch 10/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 0.9800\n",
      "Epoch 11/50\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.0435 - val_accuracy: 0.9840\n",
      "Epoch 12/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0435 - val_accuracy: 0.9840\n",
      "Epoch 13/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9800\n",
      "Epoch 14/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 0.9800\n",
      "Epoch 15/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 0.9800\n",
      "Epoch 16/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 0.9800\n",
      "Epoch 17/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0449 - val_accuracy: 0.9840\n",
      "Epoch 18/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 8.3089e-04 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 0.9800\n",
      "Epoch 19/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.7869e-04 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9800\n",
      "Epoch 20/50\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.6995e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9800\n",
      "Epoch 21/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 4.3151e-04 - accuracy: 1.0000 - val_loss: 0.0504 - val_accuracy: 0.9840\n",
      "Epoch 22/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 3.1377e-04 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 0.9800\n",
      "Epoch 23/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 2.2076e-04 - accuracy: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9800\n",
      "Epoch 24/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.9299e-04 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9800\n",
      "Epoch 25/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.3767e-04 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 0.9840\n",
      "Epoch 26/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.1310e-04 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 27/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.2231e-05 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 0.9800\n",
      "Epoch 28/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 6.6970e-05 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9800\n",
      "Epoch 29/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.1337e-05 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9800\n",
      "Epoch 30/50\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 4.3102e-05 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9800\n",
      "Epoch 31/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 3.0177e-05 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9800\n",
      "Epoch 32/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 2.5741e-05 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9800\n",
      "Epoch 33/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.8715e-05 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9800\n",
      "Epoch 34/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.5754e-05 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9800\n",
      "Epoch 35/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.2891e-05 - accuracy: 1.0000 - val_loss: 0.0636 - val_accuracy: 0.9800\n",
      "Epoch 36/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.7843e-06 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9800\n",
      "Epoch 37/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.8682e-06 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
      "Epoch 38/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.6602e-06 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9800\n",
      "Epoch 39/50\n",
      "45/45 [==============================] - 0s 6ms/step - loss: 5.3247e-06 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
      "Epoch 40/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 3.7383e-06 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
      "Epoch 41/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 2.9608e-06 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 2.5191e-06 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9800\n",
      "Epoch 43/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 2.0732e-06 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.5447e-06 - accuracy: 1.0000 - val_loss: 0.0720 - val_accuracy: 0.9800\n",
      "Epoch 45/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 1.4851e-06 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.3268e-07 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9800\n",
      "Epoch 47/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 9.0095e-07 - accuracy: 1.0000 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
      "Epoch 48/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 7.4057e-07 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 49/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 5.7729e-07 - accuracy: 1.0000 - val_loss: 0.0820 - val_accuracy: 0.9800\n",
      "Epoch 50/50\n",
      "45/45 [==============================] - 0s 5ms/step - loss: 4.9729e-07 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "# 只需要训练分类器模型即可，不需要训练特征提取器\n",
    "train_data = np.load(os.path.join(save_folder,'bottleneck_features_train.npy')) # 加载训练图片集的所有图片的VGG16-notop特征\n",
    "train_labels = np.array([0] * 450 + [1] * 450 + [2] * 450 + [3] * 450 + [4] * 450)\n",
    "# label是每个类别80张图片，共5个类别\n",
    "# 设置标签，并规范成Keras默认格式\n",
    "train_labels = to_categorical(train_labels, class_num)\n",
    "\n",
    "validation_data = np.load(os.path.join(save_folder,'bottleneck_features_val.npy'))\n",
    "validation_labels = np.array([0] * 50 + [1] * 50 + [2] * 50 + [3] * 50 + [4] * 50)\n",
    "validation_labels = to_categorical(validation_labels, class_num)\n",
    "\n",
    "# 构建分类器模型\n",
    "clf_model=my_model()\n",
    "history_ft = clf_model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画图，将训练时的acc和loss都绘制到图上\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def plot_training(history):\n",
    "    plt.figure(12)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    epochs = range(len(train_acc))\n",
    "    plt.plot(epochs, train_acc, 'b',label='train_acc')\n",
    "    plt.plot(epochs, val_acc, 'r',label='test_acc')\n",
    "    plt.title('Train and Test accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(train_loss))\n",
    "    plt.plot(epochs, train_loss, 'b',label='train_loss')\n",
    "    plt.plot(epochs, val_loss, 'r',label='test_loss')\n",
    "    plt.title('Train and Test loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-ae48555200c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-b12cc8b58471>\u001b[0m in \u001b[0;36mplot_training\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training(history_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model.save_weights(os.path.join(save_folder,'top_FC_model'))\n",
    "clf_model.save(\"../models/MobileNet/mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
