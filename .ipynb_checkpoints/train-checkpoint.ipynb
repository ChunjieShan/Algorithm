{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d28edda6ad7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlogical_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Physical GPUs,\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogical_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Logical GPUs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/framework/config.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(device_type)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mLogicalDevice\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m   \"\"\"\n\u001b[0;32m--> 372\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mlist_logical_devices\u001b[0;34m(self, device_type)\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlist_logical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;34m\"\"\"Return logical devices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logical_devices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m           pywrap_tfe.TFE_ContextOptionsSetLazyRemoteInputsCopy(\n\u001b[1;32m    514\u001b[0m               opts, self._lazy_remote_inputs_copy)\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mcontext_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: out of memory"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, random, shutil\n",
    "np.random.seed(7)\n",
    "\n",
    "FOLDER = '../data/'\n",
    "train_data_dir = os.path.join(FOLDER, 'train')\n",
    "val_data_dir = os.path.join(FOLDER, 'validation')\n",
    "train_samples_num = 2250 # train set中全部照片数\n",
    "val_samples_num = 250\n",
    "IMG_W, IMG_H, IMG_CH = 150, 150, 3 # 单张图片的大小\n",
    "batch_size = 16\n",
    "epochs = 80 # 用比较少的epochs数目做演示，节约训练时间\n",
    "class_num = 5 # 此处有5个类别\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2，准备训练集，tensorflow.keras有很多Generator可以直接处理图片的加载，增强等操作，封装的非常好\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator( # 单张图片的处理方式，train时一般都会进行图片增强\n",
    "    rescale=1. / 255, # 图片像素值为0-255，此处都乘以1/255，调整到0-1之间\n",
    "    shear_range=0.2, # 斜切\n",
    "    zoom_range=0.2, # 放大缩小范围\n",
    "    horizontal_flip=True) # 水平翻转\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( # 从文件夹中产生数据流\n",
    "    train_data_dir, # 训练集图片的文件夹\n",
    "    target_size=(IMG_W, IMG_H), # 调整后每张图片的大小\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary') # 此处是多分类问题，故而mode是categorical\n",
    "\n",
    "# 3，同样的方式准备测试集\n",
    "val_datagen = ImageDataGenerator(rescale=1. /\n",
    "                                 255) # 只需要和trainset同样的scale即可，不需增强\n",
    "val_generator = val_datagen.flow_from_directory(val_data_dir,\n",
    "                                                target_size=(IMG_W, IMG_H),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4，建立tensorflow.keras模型：模型的建立主要包括模型的搭建，模型的配置\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    # 模型的搭建：此处构建三个CNN层+2个全连接层的结构\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), strides=2, input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=2))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=2))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides=2))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(32, (1, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(16, (1, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#     model.add(Conv2D(64, (3, 3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(tf.keras.layers.BatchNormalization())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(64))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.5)) # Dropout防止过拟合\n",
    "    model.add(Dense(class_num)) # 此处多分类问题，用Dense(class_num)\n",
    "    model.add(Activation('softmax')) #多分类问题用softmax作为activation function\n",
    "\n",
    "    # 模型的配置\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy', # 定义模型的loss func，optimizer，\n",
    "        optimizer=optimizers.RMSprop(lr=1e-2, momentum=0.9), # 使用默认的lr=0.001\n",
    "        metrics=['accuracy']) # 主要优化accuracy\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    return model # 返回构建好的模型\n",
    "\n",
    "\n",
    "model = build_model(input_shape=(IMG_W, IMG_H, IMG_CH)) # 输入的图片维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 模型的训练\n",
    "history_ft = model.fit(\n",
    "    train_generator, # 数据流\n",
    "    steps_per_epoch=train_samples_num // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_samples_num // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(model, \"./simple.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_training(history):\n",
    "    plt.figure(12)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    train_acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(len(train_acc))\n",
    "    plt.plot(epochs, train_acc, 'b', label='train_acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label='test_acc')\n",
    "    plt.title('Train and Test accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(train_loss))\n",
    "    plt.plot(epochs, train_loss, 'b', label='train_loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='test_loss')\n",
    "    plt.title('Train and Test loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_training(history_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
